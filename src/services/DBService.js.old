'use strict'

const http = require('http')
const zlib = require('zlib')

const async = require('async')
const pg = require('pg')
const copyFrom = require('pg-copy-streams').from
const _ = require('lodash')

const env = require('process').env
      


// postgresql://[user[:password]@][netloc][:port][/dbname][?param1=value1&...]
const conString = (() => {
    const process = require('process')

    let user   = process.env.POSTGRES_USER
    let passwd = process.env.POSTGRES_PASSWORD || ''
    let netloc = process.env.POSTGRES_NETLOC
    let port   = process.env.POSTGRES_PORT     || ''
    let dbname = process.env.POSTGRES_DB

    return 'postgresql://' + user + (passwd && (':' + passwd)) +'@'+ netloc + (port && (':' + port)) +'/'+ dbname
})()


const censusBaseURL = "http://lehd.ces.census.gov/pub/"
const aggregation = 'gm_ns_op_u'

const loadedStateCodesQuery = "SELECT geography FROM label_geography WHERE char_length(geography) = 2;" 


const loadStatesData = (states, DDL_lock, callback) => {

    let loadData = (state, workerC, firmC, agg, cb) => {

        let tableName = `${workerC}_${firmC}_${agg}`
        let fileName  = `${tableName}.csv.gz`

        let url = `${censusBaseURL}/${state}/${env.QWI_RELEASE }/DVD-${workerC}_${firmC}/qwi_${state}_${fileName}`

        console.log('Loading data for', state, 'into', tableName)

        let timerLabel = state + ' -> ' + tableName
        console.time(timerLabel)

        return pg.connect(conString, function(err, client, done) {
            let stream = client.query(copyFrom(`COPY ${tableName} FROM STDIN DELIMITER ',' CSV HEADER`))
            let gunzipper = zlib.createGunzip()

            return http.request(url, res => {
                res.pipe(gunzipper)
                   .pipe(stream)
                   .on('finish', () => { 
                       done() 
                       console.timeEnd(timerLabel)
                       DDL_lock.message += `\n${state} loaded into ${tableName}.`
                       return cb(null) 
                   })
                   .on('error', (err) => { 
                       done() 
                       console.timeEnd(timerLabel)
                       DDL_lock.message += `\nERROR while loading ${state} into ${tableName}.`
                       return cb(err) 
                   })
            }).end()
        })
    }



    return getUploadedStates((err, res) => {

        if (err) { return callback(err) }

        let dupeStates = _.intersection(states, res)

        if (dupeStates.length) {
            DDL_lock.message += '\nThe following states aleady were uploaded: ' + JSON.stringify(dupeStates) + '.'
            console.warn('The following states aleady were uploaded:', dupeStates)
        }

        states = _.difference(states, res)

        let geoLabelLoaders = states.map(state => loadGeoLabels.bind(null, state))

        let dataLoaders = states.reduce((acc, state) => {
            for (let i = 0; i < workerCharacteristics.length; ++i) {
                for (let j = 0; j < firmCharacteristics.length; ++j) {
                    acc.push(loadData.bind(null, state, workerCharacteristics[i], firmCharacteristics[j], aggregation))
                }
            }
            return acc 
        }, [])

        // Don't want to anger the host, so we'll do serial.
        return async.series(geoLabelLoaders.concat(dataLoaders), callback)
    })
}


const getUploadedStates = (cb => 
    runQuery(loadedStateCodesQuery, (e,res) => (e) ? cb(e) : cb(null, res.rows.map(r => stateToCode[r.geography]))))

const loadAllStates = loadStatesData.bind(null, _.values(stateToCode))


module.exports = {
    runQuery       : runQuery ,
    //createTables   : createTables ,
    loadLabels     : loadLabels ,
    loadStatesData : loadStatesData ,
    loadAllStates  : loadAllStates ,
    getUploadedStates : getUploadedStates ,
}



